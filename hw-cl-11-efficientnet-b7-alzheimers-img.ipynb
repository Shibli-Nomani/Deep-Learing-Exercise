{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt #plotting\nimport numpy as np\nimport os #to access directory\nfrom tqdm import tqdm #counting files\n\nimport seaborn as sns #visual beautification\nimport cv2\nimport io #input/ouput from local\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle #shuffles matrics randomly with continuation of same pattern\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #augmentation, annotation\nfrom tensorflow.keras.applications import EfficientNetB7 #B0-B7\n\n#EarlyStopping: to avoid overfitting\n#ReduceLROnplateau: Reduce Learning Rate based on weight\n#TensorBoard: Visualization toolkit of tensorflow\n#ModelCheckpoint: save the model or weight at every epoch for improve performance and avoid repeat\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical #encoding\n\n#result checking\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom warnings import filterwarnings #ignore deprecation\nfrom PIL import Image #pillow for image open, rotate and display\n\nimport ipywidgets as widgets  #for button\nfrom IPython.display import display, clear_output ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:26:20.393069Z","iopub.execute_input":"2022-09-05T17:26:20.393768Z","iopub.status.idle":"2022-09-05T17:26:20.401020Z","shell.execute_reply.started":"2022-09-05T17:26:20.393731Z","shell.execute_reply":"2022-09-05T17:26:20.400035Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"**To see all files one by one and findout unnecessary/hidden/corrupted file, name mismatch**","metadata":{}},{"cell_type":"code","source":"#os.listddir = to show all directory\n#os.walk = to show each files with dir\n#os.path.join=merge the paths\nfor dir_name, _, filenames in os.walk(\"../input/alzheimersdisease5classdatasetadni\"):\n    for filename in filenames:\n        print(os.path.join(dir_name, filename))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#labels based on classwise folder name in directory\nlabels=[\"Final AD JPEG\", \"Final CN JPEG\", \"Final EMCI JPEG\", \"Final LMCI JPEG\", \"Final MCI JPEG\"]","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:26:36.220574Z","iopub.execute_input":"2022-09-05T17:26:36.221538Z","iopub.status.idle":"2022-09-05T17:26:36.226332Z","shell.execute_reply.started":"2022-09-05T17:26:36.221500Z","shell.execute_reply":"2022-09-05T17:26:36.225076Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"**Prepare train test Data Together**","metadata":{}},{"cell_type":"code","source":"X_train=[]\ny_train=[]\n\nimage_size=162\nfor i in labels:\n    folderDirectory = os.path.join(\"../input/alzheimersdisease5classdatasetadni/Alzheimers-ADNI\", \"train\", i) #tagging labels by i\n    for j in tqdm(os.listdir(folderDirectory)): #tqdm counting\n        image=cv2.imread(os.path.join(folderDirectory, j)) #image to array\n        image=cv2.resize(image, (image_size, image_size))\n        \n        X_train.append(image)\n        y_train.append(i)\nfor i in labels:\n    folderDirectory=os.path.join(\"../input/alzheimersdisease5classdatasetadni/Alzheimers-ADNI\",\"test\", i)\n    for j in tqdm(os.listdir(folderDirectory)):\n        image=cv2.imread(os.path.join(folderDirectory, j))\n        image=cv2.resize(image, (image_size,image_size))\n        \n        X_train.append(image)\n        y_train.append(i)\n#now we need to convert it to numpy array to make it workable\nX_train=np.array(X_train)\ny_train = np.array(y_train)\n   \n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:34.354725Z","iopub.execute_input":"2022-09-05T17:42:34.355098Z","iopub.status.idle":"2022-09-05T17:42:37.119985Z","shell.execute_reply.started":"2022-09-05T17:42:34.355066Z","shell.execute_reply":"2022-09-05T17:42:37.118702Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"print(\"X_train Shape:\", X_train.shape)\nprint(\"y_train Shape:\", y_train.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:41.652455Z","iopub.execute_input":"2022-09-05T17:42:41.653326Z","iopub.status.idle":"2022-09-05T17:42:41.658992Z","shell.execute_reply.started":"2022-09-05T17:42:41.653290Z","shell.execute_reply":"2022-09-05T17:42:41.657778Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"**Count unique value for each class**","metadata":{}},{"cell_type":"code","source":"_,y_trainImageInfo= np.unique(y_train, return_counts =True)\nprint(\"Final AD JPEG:\")\nprint(\"counts:\", y_trainImageInfo[0])\nprint(\"Final CN JPEG:\")\nprint(\"counts:\", y_trainImageInfo[1])\nprint(\"Final EMCI JPEG:\")\nprint(\"counts:\", y_trainImageInfo[2])\nprint(\"Final LMCI JPEG:\")\nprint(\"counts:\", y_trainImageInfo[3])\nprint(\"Final MCI JPEG:\")\nprint(\"counts:\", y_trainImageInfo[4])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:45.521491Z","iopub.execute_input":"2022-09-05T17:42:45.522489Z","iopub.status.idle":"2022-09-05T17:42:45.531442Z","shell.execute_reply.started":"2022-09-05T17:42:45.522440Z","shell.execute_reply":"2022-09-05T17:42:45.530323Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"#shuffle based on randomState\nX_train, y_train = shuffle(X_train, y_train, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:48.158852Z","iopub.execute_input":"2022-09-05T17:42:48.159437Z","iopub.status.idle":"2022-09-05T17:42:48.362172Z","shell.execute_reply.started":"2022-09-05T17:42:48.159396Z","shell.execute_reply":"2022-09-05T17:42:48.361083Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of X_train:\",'\\n',X_train.shape)\nprint(\"Shape of y_train:\",'\\n',y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:50.688336Z","iopub.execute_input":"2022-09-05T17:42:50.689491Z","iopub.status.idle":"2022-09-05T17:42:50.695830Z","shell.execute_reply.started":"2022-09-05T17:42:50.689445Z","shell.execute_reply":"2022-09-05T17:42:50.694367Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"print(y_train[0])\nprint(y_train[100])\nprint(y_train[200])\nprint(y_train[500])\nprint(y_train[750])\nprint(y_train[1000])\nprint(y_train[1295])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:52.625317Z","iopub.execute_input":"2022-09-05T17:42:52.626268Z","iopub.status.idle":"2022-09-05T17:42:52.633451Z","shell.execute_reply.started":"2022-09-05T17:42:52.626210Z","shell.execute_reply":"2022-09-05T17:42:52.632081Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"**Train and Test Split**","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test =train_test_split(X_train, y_train, test_size=0.10, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:57.576433Z","iopub.execute_input":"2022-09-05T17:42:57.576991Z","iopub.status.idle":"2022-09-05T17:42:57.690600Z","shell.execute_reply.started":"2022-09-05T17:42:57.576956Z","shell.execute_reply":"2022-09-05T17:42:57.689595Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"print(\"X_train:\", X_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:42:59.675429Z","iopub.execute_input":"2022-09-05T17:42:59.675800Z","iopub.status.idle":"2022-09-05T17:42:59.682013Z","shell.execute_reply.started":"2022-09-05T17:42:59.675762Z","shell.execute_reply":"2022-09-05T17:42:59.680712Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"print(\"y_train Index 0:\", y_train[0])\nprint(\"y_test Index 0:\", y_test[0])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:01.445364Z","iopub.execute_input":"2022-09-05T17:43:01.446291Z","iopub.status.idle":"2022-09-05T17:43:01.452811Z","shell.execute_reply.started":"2022-09-05T17:43:01.446235Z","shell.execute_reply":"2022-09-05T17:43:01.451497Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"**Categorical/label/one hot encoding**","metadata":{}},{"cell_type":"code","source":"y_train_new=[]\ny_test_new=[]\n\nfor i in y_train:\n    y_train_new.append(labels.index(i)) #indexing value of y_train\ny_train = y_train_new\ny_train = to_categorical(y_train)\n\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:04.560307Z","iopub.execute_input":"2022-09-05T17:43:04.560902Z","iopub.status.idle":"2022-09-05T17:43:04.568299Z","shell.execute_reply.started":"2022-09-05T17:43:04.560866Z","shell.execute_reply":"2022-09-05T17:43:04.567166Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"print(\"shape of y_train\", y_train.shape)\nprint(\"array of y_test\", y_test.shape)\nprint(\"array of y_train\", y_train)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:06.550487Z","iopub.execute_input":"2022-09-05T17:43:06.551467Z","iopub.status.idle":"2022-09-05T17:43:06.558577Z","shell.execute_reply.started":"2022-09-05T17:43:06.551419Z","shell.execute_reply":"2022-09-05T17:43:06.557477Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"markdown","source":"**max value in array for respective image class**","metadata":{}},{"cell_type":"code","source":"#maxma value of that array of respective image\nprint(np.argmax(y_train[0]))\nprint(np.argmax(y_train[200]))\nprint(np.argmax(y_train[450]))","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:09.325569Z","iopub.execute_input":"2022-09-05T17:43:09.326799Z","iopub.status.idle":"2022-09-05T17:43:09.333598Z","shell.execute_reply.started":"2022-09-05T17:43:09.326757Z","shell.execute_reply":"2022-09-05T17:43:09.332433Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"code","source":"efficient = EfficientNetB7(weights =\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3))\n","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:11.541133Z","iopub.execute_input":"2022-09-05T17:43:11.541741Z","iopub.status.idle":"2022-09-05T17:43:16.766280Z","shell.execute_reply.started":"2022-09-05T17:43:11.541707Z","shell.execute_reply":"2022-09-05T17:43:16.765226Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:19.121281Z","iopub.execute_input":"2022-09-05T17:43:19.121642Z","iopub.status.idle":"2022-09-05T17:43:19.126991Z","shell.execute_reply.started":"2022-09-05T17:43:19.121612Z","shell.execute_reply":"2022-09-05T17:43:19.125892Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"#pooling can be avg or max\n#dropout range 0.3 -0.5 which means 30-50% neurons will be dropped to avoid overfitting\nmodel=efficient.output\nmodel=tf.keras.layers.GlobalMaxPooling2D()(model)\nmodel=tf.keras.layers.Dropout(0.5)(model)\nmodel=tf.keras.layers.Dense(5, activation=\"softmax\")(model)\nmodel=tf.keras.models.Model(inputs=efficient.input, outputs=model)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:36.862731Z","iopub.execute_input":"2022-09-05T17:43:36.863098Z","iopub.status.idle":"2022-09-05T17:43:36.926401Z","shell.execute_reply.started":"2022-09-05T17:43:36.863068Z","shell.execute_reply":"2022-09-05T17:43:36.925482Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:39.516235Z","iopub.execute_input":"2022-09-05T17:43:39.516881Z","iopub.status.idle":"2022-09-05T17:43:39.611888Z","shell.execute_reply.started":"2022-09-05T17:43:39.516842Z","shell.execute_reply":"2022-09-05T17:43:39.610866Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"#loss for categorical value, adam perform best\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=\"adam\", \n              metrics =[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:46.564128Z","iopub.execute_input":"2022-09-05T17:43:46.564521Z","iopub.status.idle":"2022-09-05T17:43:46.587264Z","shell.execute_reply.started":"2022-09-05T17:43:46.564491Z","shell.execute_reply":"2022-09-05T17:43:46.586126Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"#.h5 = Hierarchical Data Format Ver. 5 file, verbose =1, to see execution\ntensorboard= TensorBoard(log_dir=\"logs\")\ncheckpoint= ModelCheckpoint(\"efficient.h5\",\n                           monitor=\"val_accuracy\", verbose=1,\n                           mode=\"auto\", save_best_only=True)\n#monitor: quantity to be monitored.     \n#factor: factor by which the learning rate will be reduced. \n#patience: number of epochs with no improvement after which learning rate will be reduced.     \n#verbose: int. 0: quiet, 1: update messages.\n#min_delta: early stopping of epochs\nreduce_lr=ReduceLROnPlateau(monitor=\"val_accuracy\",\n                           factor=0.5,\n                           patience=3,verbose=1,\n                           mode=\"auto\", min_delta=0.001)\n\n                               ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:48.659998Z","iopub.execute_input":"2022-09-05T17:43:48.660375Z","iopub.status.idle":"2022-09-05T17:43:49.034475Z","shell.execute_reply.started":"2022-09-05T17:43:48.660345Z","shell.execute_reply":"2022-09-05T17:43:49.033394Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"markdown","source":"**Fit the model**","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train,\n                   validation_split=0.1,\n                   epochs=15, verbose=1,\n                   batch_size=32,\n                   callbacks =[tensorboard, checkpoint, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:43:56.993519Z","iopub.execute_input":"2022-09-05T17:43:56.993880Z","iopub.status.idle":"2022-09-05T17:51:45.126553Z","shell.execute_reply.started":"2022-09-05T17:43:56.993848Z","shell.execute_reply":"2022-09-05T17:51:45.125495Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"def accuracy_loss_plot (history):\n    fig = plt.figure(figsize=(10,10))\n    \n    plt.subplot(221)\n    plt.plot(history.history[\"accuracy\"], 'bo--', label=\"accuracy\")\n    plt.plot(history.history['val_accuracy'], 'ro--', label=\"val_accuracy\")\n    plt.title(\"Training Data Accuracy Measurements\")\n    plt.xlabel(\"Number of epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.grid()\n    plt.legend()\n    plt.tight_layout()\n    \n    plt.subplot(222)\n    plt.plot(history.history[\"loss\"], \"bo--\", label=\"loss\")\n    plt.plot(history.history[\"val_loss\"], \"ro--\", label = \"val_loss\")\n    plt.title(\"Training Data Loss\")\n    plt.xlabel(\"Number of epochs\")\n    plt.ylabel(\"loss\")\n    plt.grid()\n    plt.legend()\n    plt.tight_layout()\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:51:45.129341Z","iopub.execute_input":"2022-09-05T17:51:45.129982Z","iopub.status.idle":"2022-09-05T17:51:45.139398Z","shell.execute_reply.started":"2022-09-05T17:51:45.129944Z","shell.execute_reply":"2022-09-05T17:51:45.138387Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"accuracy_loss_plot(history)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:51:45.140971Z","iopub.execute_input":"2022-09-05T17:51:45.141496Z","iopub.status.idle":"2022-09-05T17:51:45.568239Z","shell.execute_reply.started":"2022-09-05T17:51:45.141462Z","shell.execute_reply":"2022-09-05T17:51:45.567162Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"X_testloss=model.evaluate(X_test, y_test, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:51:56.725996Z","iopub.execute_input":"2022-09-05T17:51:56.726378Z","iopub.status.idle":"2022-09-05T17:51:58.051914Z","shell.execute_reply.started":"2022-09-05T17:51:56.726346Z","shell.execute_reply":"2022-09-05T17:51:58.050860Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)\ny_pred=np.argmax(y_pred, axis=1)\ny_test_new = np.argmax(y_test, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:52:02.964799Z","iopub.execute_input":"2022-09-05T17:52:02.965169Z","iopub.status.idle":"2022-09-05T17:52:07.988664Z","shell.execute_reply.started":"2022-09-05T17:52:02.965136Z","shell.execute_reply":"2022-09-05T17:52:07.987490Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nprint(classification_report(y_test_new, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:52:10.598978Z","iopub.execute_input":"2022-09-05T17:52:10.599618Z","iopub.status.idle":"2022-09-05T17:52:10.613569Z","shell.execute_reply.started":"2022-09-05T17:52:10.599563Z","shell.execute_reply":"2022-09-05T17:52:10.612509Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"cm=confusion_matrix(y_test_new, y_pred)\nfig, ax = plt.subplots(figsize=(20,5)) \nsns.heatmap(cm, annot=True, linewidths=2, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:52:18.446991Z","iopub.execute_input":"2022-09-05T17:52:18.447698Z","iopub.status.idle":"2022-09-05T17:52:18.746110Z","shell.execute_reply.started":"2022-09-05T17:52:18.447659Z","shell.execute_reply":"2022-09-05T17:52:18.745121Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"display_c_m = ConfusionMatrixDisplay(cm, display_labels=labels)\nfig, ax = plt.subplots(figsize=(25,10)) \ndisplay_c_m.plot(cmap='mako',ax=ax,xticks_rotation=60)\nplt.title(\"Confusion Metrics\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:52:30.488127Z","iopub.execute_input":"2022-09-05T17:52:30.488765Z","iopub.status.idle":"2022-09-05T17:52:30.792388Z","shell.execute_reply.started":"2022-09-05T17:52:30.488723Z","shell.execute_reply":"2022-09-05T17:52:30.791237Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"def imagePrediction(upload):\n    for name, fileinfo  in uploader.value.items():\n        image = Image.open(io.BytesIO(fileinfo['content'])) #Image for PIL and io=input/output locall\n    \n    images = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n    images = cv2.resize(images,(162, 162))\n    images = images.reshape(1, 162, 162, 3)\n    prd = model.predict(images)\n    prd = np.argmax(prd, axis = 1)[0]\n    \n    if prd==0:\n        prd=\"Final AD JPEG\"\n    elif prd==1:\n        prd=\"Final CN JPEG\"\n    elif prd==2:\n        prd=\"Final EMCI JPEG\"\n    elif prd==3:\n        prd=\"Final LMCI JPEG\"\n    elif prd==4:\n        prd=\"Final MCI JPEG\"\n    \n    if prd!=1:\n        print(f\"Model Predict That is a {prd}\")\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:52:50.276457Z","iopub.execute_input":"2022-09-05T17:52:50.277034Z","iopub.status.idle":"2022-09-05T17:52:50.284754Z","shell.execute_reply.started":"2022-09-05T17:52:50.276999Z","shell.execute_reply":"2022-09-05T17:52:50.283479Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"markdown","source":"**To upload files/images**","metadata":{}},{"cell_type":"code","source":"uploader = widgets.FileUpload()\ndisplay(uploader)","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:53:03.252702Z","iopub.execute_input":"2022-09-05T17:53:03.253072Z","iopub.status.idle":"2022-09-05T17:53:03.266509Z","shell.execute_reply.started":"2022-09-05T17:53:03.253043Z","shell.execute_reply":"2022-09-05T17:53:03.265345Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"markdown","source":"**Image Predition for Alzheimers**","metadata":{}},{"cell_type":"code","source":"button=widgets.Button(description=\"Predict\")\nout=widgets.Output()\n\ndef on_button_click(_): \n    with out:\n        clear_output()\n        try: \n            imagePrediction(uploader)\n        except:\n            print(\"Enter the correct image file\")\nbutton.on_click(on_button_click)\nwidgets.VBox([button, out])\n            ","metadata":{"execution":{"iopub.status.busy":"2022-09-05T17:39:43.794221Z","iopub.execute_input":"2022-09-05T17:39:43.794700Z","iopub.status.idle":"2022-09-05T17:39:43.819561Z","shell.execute_reply.started":"2022-09-05T17:39:43.794668Z","shell.execute_reply":"2022-09-05T17:39:43.818446Z"},"trusted":true},"execution_count":112,"outputs":[]}]}